{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "oxiZ42B4SwQ-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# from torchsummaryX import summary\n",
    "from tests_hw4 import test_prediction, test_generation\n",
    "from tqdm import tqdm\n",
    "import gc \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Dec  3 04:24:32 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            On   | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   56C    P0    29W /  70W |  12399MiB / 15360MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     36170      C   ...a/envs/pytorch/bin/python    12395MiB |\n",
      "+-----------------------------------------------------------------------------+\n",
      "Device:  cuda\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Device: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: define other hyperparameters here\n",
    "NUM_EPOCHS = 100\n",
    "BATCH_SIZE = 30\n",
    "SEQ_LEN = 50\n",
    "EMB_DIM = 200\n",
    "HIDDEN_SIZE = 200\n",
    "LR = 0.001\n",
    "SEQ_LEN_PROB = 0.95\n",
    "SEQ_LEN_STD = 5\n",
    "LSTM_DROPOUT = 0.3\n",
    "LSTM_LAYERS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "id": "x5znxQhLSwRC"
   },
   "outputs": [],
   "source": [
    "# load all that we need\n",
    "\n",
    "dataset = np.load('../dataset/wiki.train.npy', allow_pickle=True)\n",
    "devset = np.load('../dataset/wiki.valid.npy', allow_pickle=True)\n",
    "fixtures_pred = np.load('../fixtures/prediction.npz')  # dev\n",
    "fixtures_gen = np.load('../fixtures/generation.npy')  # dev\n",
    "fixtures_pred_test = np.load('../fixtures/prediction_test.npz')  # test\n",
    "fixtures_gen_test = np.load('../fixtures/generation_test.npy')  # test\n",
    "vocab = np.load('../dataset/vocab.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "id": "OZNrJ8XvSwRF"
   },
   "outputs": [],
   "source": [
    "# data loader\n",
    "\n",
    "class DataLoaderForLanguageModeling(DataLoader):\n",
    "    \"\"\"\n",
    "        TODO: Define data loader logic here\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, batch_size, seq_len, shuffle=True):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.seq_len = seq_len\n",
    "        self.shuffle = shuffle\n",
    "        self.num_batches = (len(np.concatenate(dataset))-1)//batch_size\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "      return int(self.num_batches // self.seq_len)\n",
    "      \n",
    "    def __iter__(self):\n",
    "        \"\"\"\n",
    "            You may implement some of the techniques in https://arxiv.org/pdf/1708.02182.pdf\n",
    "            example: Variable length backpropagation sequences (Section 4.1)\n",
    "        \"\"\"\n",
    "        ## dataset = Array of articles; article = array of ints\n",
    "        # 1. Randomly shuffle all the articles from the WikiText-2 dataset.\n",
    "        if(self.shuffle):\n",
    "            np.random.shuffle(self.dataset)\n",
    "        # 2. Concatenate all text in one long string.\n",
    "        data = np.concatenate(self.dataset)\n",
    "        # 3. Group the sequences into batches.\n",
    "        self.num_batches = (len(data) - 1) // self.batch_size # One less since need offset for label\n",
    "        inputs  = data[0:self.num_batches * self.batch_size].reshape(self.batch_size,-1)\n",
    "        targets = data[1:self.num_batches * self.batch_size + 1].reshape(self.batch_size,-1)\n",
    "        inputs = torch.from_numpy(inputs).to(dtype=torch.long)\n",
    "        targets = torch.from_numpy(targets).to(dtype=torch.long)\n",
    "        # 4. Run a loop that returns a tuple of (input, label) on every iteration with yield.\n",
    "        offset = 0\n",
    "        cur_seq_len = self.seq_len\n",
    "        while((offset + cur_seq_len) < inputs.shape[1]):\n",
    "            input_ = inputs[:, offset : offset+cur_seq_len]\n",
    "            target = targets[:, offset : offset+cur_seq_len]\n",
    "            offset += cur_seq_len\n",
    "            yield (input_, target)\n",
    "            # Update cur_seq_len\n",
    "            cur_seq_len = self.seq_len if (np.random.rand() < SEQ_LEN_PROB) else self.seq_len//2\n",
    "            cur_seq_len_temp = int(np.random.normal(cur_seq_len, SEQ_LEN_STD))\n",
    "            cur_seq_len = cur_seq_len_temp if (cur_seq_len_temp > 0) else cur_seq_len\n",
    "\n",
    "# # TEST       \n",
    "# test = DataLoaderForLanguageModeling(dataset, BATCH_SIZE, SEQ_LEN)\n",
    "# for i,(test_inputs, test_targets) in enumerate(test.__iter__()):\n",
    "#     print('---------')\n",
    "#     print('iter: ', i)\n",
    "#     print('shape: ', test_inputs.shape)\n",
    "#     print('type: ', test_inputs.dtype, ', ', test_targets.dtype)\n",
    "#     for batch_idx in range(0, test.batch_size):\n",
    "#         tmpstr1 = ['    ']\n",
    "#         tmpstr2 = ['    ']\n",
    "#         for seq_idx in range(0, test.seq_len):\n",
    "#             tmpstr1.append(vocab[test_inputs[batch_idx, seq_idx]])\n",
    "#             tmpstr2.append(vocab[test_targets[batch_idx, seq_idx]])\n",
    "#         print(' '.join(tmpstr1))\n",
    "#         print(' '.join(tmpstr2))\n",
    "#         print()\n",
    "#     if(i > 3):\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "id": "Zt-7YsTYSwRI"
   },
   "outputs": [],
   "source": [
    "# model\n",
    "\n",
    "class Model(nn.Module):\n",
    "    \"\"\"\n",
    "        TODO: Define your model here\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size:int, embedding_dim:int, hidden_size:int):\n",
    "        super(Model, self).__init__()\n",
    "        # Embedding: vocab_size -> embedding_dim\n",
    "        # LSTM: embedding_dim -> hidden_size\n",
    "        # Classifier: hidden_size -> vocab_size\n",
    "        self.embedding = nn.Sequential(\n",
    "            nn.Embedding(vocab_size, embedding_dim),\n",
    "        )\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size = embedding_dim,\n",
    "            hidden_size = hidden_size,\n",
    "            num_layers = LSTM_LAYERS,\n",
    "            # bidirectional = True,\n",
    "            dropout = LSTM_DROPOUT,\n",
    "            batch_first=True)\n",
    "        self.classifier = nn.Sequential(\n",
    "            torch.nn.Linear(hidden_size * 1, vocab_size),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x, h_in = None):\n",
    "        # Feel free to add extra arguments to forward (like an argument to pass in the hiddens)\n",
    "        out = self.embedding(x)\n",
    "        out, h_out = self.lstm(out, h_in) if h_in else self.lstm(out)\n",
    "        out = self.classifier(out)\n",
    "        return out, h_out\n",
    "\n",
    "# # TEST\n",
    "# model = Model(len(vocab), EMB_DIM, HIDDEN_SIZE)\n",
    "# test_input = torch.randint(0, len(vocab), (BATCH_SIZE, SEQ_LEN), dtype=torch.long)\n",
    "# test_output, test_hidden = model(test_input)\n",
    "# print('Input : ', test_input.shape, ', ', test_input.dtype)\n",
    "# print('Output: ', test_output.shape, ', ', test_output.dtype) # (batch, seq_len, vocab_size)\n",
    "# # summary(model, test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "id": "kIvZOIfjSwRK"
   },
   "outputs": [],
   "source": [
    "# model trainer\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, loader, max_epochs=1, run_id='exp'):\n",
    "        \"\"\"\n",
    "            Use this class to train your model\n",
    "        \"\"\"\n",
    "        # feel free to add any other parameters here\n",
    "        self.model = model\n",
    "        self.loader = loader\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.predictions = []\n",
    "        self.predictions_test = []\n",
    "        self.generated_logits = []\n",
    "        self.generated = []\n",
    "        self.generated_logits_test = []\n",
    "        self.generated_test = []\n",
    "        self.epochs = 0\n",
    "        self.max_epochs = max_epochs\n",
    "        self.run_id = run_id\n",
    "        \n",
    "        # TODO: Define your optimizer and criterion here\n",
    "        # feel free to define a learning rate scheduler as well if you want\n",
    "        self.optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "        self.criterion = nn.CrossEntropyLoss() # Correct???\n",
    "\n",
    "    def train(self):\n",
    "        self.model.train() # set to training mode\n",
    "        epoch_loss = 0\n",
    "        num_batches = 0\n",
    "        batch_bar = tqdm(total=len(self.loader), dynamic_ncols=True, leave=False, position=0, desc='Batch')\n",
    "        for batch_num, (inputs, targets) in enumerate(self.loader):\n",
    "            epoch_loss += self.train_batch(inputs, targets)\n",
    "            batch_bar.update()\n",
    "        epoch_loss = epoch_loss / (batch_num + 1)\n",
    "        print('[TRAIN]  Epoch [%d/%d]   Loss: %.4f'\n",
    "                      % (self.epochs + 1, self.max_epochs, epoch_loss))\n",
    "        self.train_losses.append(epoch_loss)\n",
    "\n",
    "    def train_batch(self, inputs, targets):\n",
    "        \"\"\" \n",
    "            TODO: Define code for training a single batch of inputs\n",
    "            \n",
    "            :return \n",
    "                    (float) loss value\n",
    "        \"\"\"\n",
    "        self.optimizer.zero_grad()\n",
    "        # Forwards\n",
    "        inputs = inputs.to(device)\n",
    "        outputs, _ = self.model(inputs)\n",
    "        # Compute loss\n",
    "        targets = targets.to(device)\n",
    "        loss = self.criterion(\n",
    "            outputs.reshape(-1, outputs.shape[2]), # (instances, classes)\n",
    "            targets.reshape(-1) # (instances, )\n",
    "        )\n",
    "        # Backwards\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return loss\n",
    "\n",
    "    \n",
    "    def test(self):\n",
    "        # don't change these\n",
    "        self.model.eval() # set to eval mode\n",
    "        predictions = TestLanguageModel.predict(fixtures_pred['inp'], self.model) # get predictions\n",
    "        self.predictions.append(predictions)\n",
    "        generated_logits = TestLanguageModel.generate(fixtures_gen, 10, self.model) # generated predictions for 10 words\n",
    "        generated_logits_test = TestLanguageModel.generate(fixtures_gen_test, 10, self.model)\n",
    "        nll = test_prediction(predictions, fixtures_pred['out'])\n",
    "        generated = test_generation(fixtures_gen, generated_logits, vocab)\n",
    "        generated_test = test_generation(fixtures_gen_test, generated_logits_test, vocab)\n",
    "        self.val_losses.append(nll)\n",
    "        \n",
    "        self.generated.append(generated)\n",
    "        self.generated_test.append(generated_test)\n",
    "        self.generated_logits.append(generated_logits)\n",
    "        self.generated_logits_test.append(generated_logits_test)\n",
    "        \n",
    "        # generate predictions for test data\n",
    "        predictions_test = TestLanguageModel.predict(fixtures_pred_test['inp'], self.model) # get predictions\n",
    "        self.predictions_test.append(predictions_test)\n",
    "            \n",
    "        print('[VAL]  Epoch [%d/%d]   Loss: %.4f'\n",
    "                      % (self.epochs + 1, self.max_epochs, nll))\n",
    "        self.epochs += 1\n",
    "\n",
    "        return nll\n",
    "\n",
    "    def save(self):\n",
    "        # don't change these\n",
    "        model_path = os.path.join('experiments', self.run_id, 'model-{}.pkl'.format(self.epochs))\n",
    "        torch.save({'state_dict': self.model.state_dict()},\n",
    "            model_path)\n",
    "        np.save(os.path.join('experiments', self.run_id, 'predictions-{}.npy'.format(self.epochs)), self.predictions[-1])\n",
    "        np.save(os.path.join('experiments', self.run_id, 'predictions-test-{}.npy'.format(self.epochs)), self.predictions_test[-1])\n",
    "        np.save(os.path.join('experiments', self.run_id, 'generated_logits-{}.npy'.format(self.epochs)), self.generated_logits[-1])\n",
    "        np.save(os.path.join('experiments', self.run_id, 'generated_logits-test-{}.npy'.format(self.epochs)), self.generated_logits_test[-1])\n",
    "        with open(os.path.join('experiments', self.run_id, 'generated-{}.txt'.format(self.epochs)), 'w') as fw:\n",
    "            fw.write(self.generated[-1])\n",
    "        with open(os.path.join('experiments', self.run_id, 'generated-{}-test.txt'.format(self.epochs)), 'w') as fw:\n",
    "            fw.write(self.generated_test[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "id": "xPI7_kZRSwRN"
   },
   "outputs": [],
   "source": [
    "class TestLanguageModel:\n",
    "    def predict(inp, model):\n",
    "        \"\"\"\n",
    "            TODO: write prediction code here\n",
    "            \n",
    "            :param inp:\n",
    "            :return: a np.ndarray of logits\n",
    "        \"\"\"\n",
    "        outputs, _ = model(torch.Tensor(inp).long().to(device))\n",
    "        # predictions = torch.argmax(outputs[:,-1,:], dim=1).unsqueeze(0)\n",
    "        predictions = outputs[:,-1,:]\n",
    "        return predictions.cpu().detach().numpy()\n",
    "\n",
    "        \n",
    "    def generate(inp, forward, model):\n",
    "        \"\"\"\n",
    "            TODO: write generation code here\n",
    "\n",
    "            Generate a sequence of words given a starting sequence.\n",
    "            :param inp: Initial sequence of words (batch size, length)\n",
    "            :param forward: number of additional words to generate\n",
    "            :return: generated words (batch size, forward)\n",
    "        \"\"\"        \n",
    "        new_words = []\n",
    "        hidden = None\n",
    "        cur_inp = torch.clone(torch.Tensor(inp).long())\n",
    "        for i in range(0, forward):\n",
    "          out, hidden = model(cur_inp.to(device), hidden)\n",
    "          cur_new_words = torch.argmax(out, dim=2)[:,-1] # Only grab last word per sequence for each batch\n",
    "          new_words.append(cur_new_words)\n",
    "          cur_inp = torch.unsqueeze(cur_new_words, dim=1) # (batch,) -> (batch,seq)\n",
    "        new_words = torch.stack(new_words, dim=1) # (batch, forward)\n",
    "        return new_words.cpu().detach().numpy()\n",
    "\n",
    "# # TEST\n",
    "# test_input = torch.randint(0, len(vocab), (BATCH_SIZE, SEQ_LEN))\n",
    "# test_model = Model(len(vocab), EMB_DIM, HIDDEN_SIZE)\n",
    "# test_output = TestLanguageModel.predict(test_input, test_model)\n",
    "# print('Test predict : ', test_output.shape)\n",
    "# test_output = TestLanguageModel.generate(test_input, 20, test_model)\n",
    "# print('Test generate: ', test_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "id": "2HCVG5YISwRW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving models, predictions, and generated words to ./experiments/1670055271\n"
     ]
    }
   ],
   "source": [
    "run_id = str(int(time.time()))\n",
    "if not os.path.exists('./experiments'):\n",
    "    os.mkdir('./experiments')\n",
    "os.mkdir('./experiments/%s' % run_id)\n",
    "print(\"Saving models, predictions, and generated words to ./experiments/%s\" % run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "id": "DbHH6zXTSwRa"
   },
   "outputs": [],
   "source": [
    "model = Model(len(vocab), embedding_dim=EMB_DIM, hidden_size=HIDDEN_SIZE).to(device)\n",
    "\n",
    "loader = DataLoaderForLanguageModeling(\n",
    "    dataset=dataset, \n",
    "    batch_size=BATCH_SIZE,\n",
    "    seq_len=SEQ_LEN,\n",
    "    shuffle=True\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model, \n",
    "    loader=loader, \n",
    "    max_epochs=NUM_EPOCHS, \n",
    "    run_id=run_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "id": "7D8wTJkBSwRc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_nll:  4.586572\n",
      "Epoch:  1 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [1/100]   Loss: 7.0412\n",
      "[VAL]  Epoch [1/100]   Loss: 6.1084\n",
      "Epoch:  2 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [2/100]   Loss: 6.1670\n",
      "[VAL]  Epoch [2/100]   Loss: 5.4204\n",
      "Epoch:  3 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [3/100]   Loss: 5.7264\n",
      "[VAL]  Epoch [3/100]   Loss: 5.1344\n",
      "Epoch:  4 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [4/100]   Loss: 5.4759\n",
      "[VAL]  Epoch [4/100]   Loss: 4.9271\n",
      "Epoch:  5 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [5/100]   Loss: 5.2789\n",
      "[VAL]  Epoch [5/100]   Loss: 4.8629\n",
      "Epoch:  6 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [6/100]   Loss: 5.1128\n",
      "[VAL]  Epoch [6/100]   Loss: 4.7262\n",
      "Epoch:  7 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [7/100]   Loss: 4.9697\n",
      "[VAL]  Epoch [7/100]   Loss: 4.6850\n",
      "Epoch:  8 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [8/100]   Loss: 4.8496\n",
      "[VAL]  Epoch [8/100]   Loss: 4.6215\n",
      "Epoch:  9 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [9/100]   Loss: 4.7442\n",
      "[VAL]  Epoch [9/100]   Loss: 4.6385\n",
      "Epoch:  10 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [10/100]   Loss: 4.6520\n",
      "[VAL]  Epoch [10/100]   Loss: 4.6460\n",
      "Epoch:  11 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [11/100]   Loss: 4.5735\n",
      "[VAL]  Epoch [11/100]   Loss: 4.5928\n",
      "Epoch:  12 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [12/100]   Loss: 4.5009\n",
      "[VAL]  Epoch [12/100]   Loss: 4.6603\n",
      "Epoch:  13 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [13/100]   Loss: 4.4352\n",
      "[VAL]  Epoch [13/100]   Loss: 4.6125\n",
      "Epoch:  14 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [14/100]   Loss: 4.3782\n",
      "[VAL]  Epoch [14/100]   Loss: 4.6148\n",
      "Epoch:  15 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [15/100]   Loss: 4.3207\n",
      "[VAL]  Epoch [15/100]   Loss: 4.6484\n",
      "Epoch:  16 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [16/100]   Loss: 4.2669\n",
      "[VAL]  Epoch [16/100]   Loss: 4.5758\n",
      "Saving model, predictions and generated output for epoch 15 with NLL: 4.575823\n",
      "Epoch:  17 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [17/100]   Loss: 4.2200\n",
      "[VAL]  Epoch [17/100]   Loss: 4.6956\n",
      "Epoch:  18 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [18/100]   Loss: 4.1740\n",
      "[VAL]  Epoch [18/100]   Loss: 4.6989\n",
      "Epoch:  19 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [19/100]   Loss: 4.1323\n",
      "[VAL]  Epoch [19/100]   Loss: 4.6569\n",
      "Epoch:  20 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [20/100]   Loss: 4.0926\n",
      "[VAL]  Epoch [20/100]   Loss: 4.6908\n",
      "Epoch:  21 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [21/100]   Loss: 4.0532\n",
      "[VAL]  Epoch [21/100]   Loss: 4.6378\n",
      "Epoch:  22 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [22/100]   Loss: 4.0182\n",
      "[VAL]  Epoch [22/100]   Loss: 4.6411\n",
      "Epoch:  23 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [23/100]   Loss: 3.9864\n",
      "[VAL]  Epoch [23/100]   Loss: 4.6563\n",
      "Epoch:  24 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [24/100]   Loss: 3.9518\n",
      "[VAL]  Epoch [24/100]   Loss: 4.6949\n",
      "Epoch:  25 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [25/100]   Loss: 3.9219\n",
      "[VAL]  Epoch [25/100]   Loss: 4.7608\n",
      "Epoch:  26 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [26/100]   Loss: 3.8897\n",
      "[VAL]  Epoch [26/100]   Loss: 4.6707\n",
      "Epoch:  27 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [27/100]   Loss: 3.8637\n",
      "[VAL]  Epoch [27/100]   Loss: 4.6778\n",
      "Epoch:  28 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [28/100]   Loss: 3.8358\n",
      "[VAL]  Epoch [28/100]   Loss: 4.7814\n",
      "Epoch:  29 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [29/100]   Loss: 3.8069\n",
      "[VAL]  Epoch [29/100]   Loss: 4.7571\n",
      "Epoch:  30 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [30/100]   Loss: 3.7847\n",
      "[VAL]  Epoch [30/100]   Loss: 4.6969\n",
      "Epoch:  31 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [31/100]   Loss: 3.7617\n",
      "[VAL]  Epoch [31/100]   Loss: 4.7675\n",
      "Epoch:  32 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [32/100]   Loss: 3.7380\n",
      "[VAL]  Epoch [32/100]   Loss: 4.7360\n",
      "Epoch:  33 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [33/100]   Loss: 3.7139\n",
      "[VAL]  Epoch [33/100]   Loss: 4.7502\n",
      "Epoch:  34 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [34/100]   Loss: 3.6935\n",
      "[VAL]  Epoch [34/100]   Loss: 4.8309\n",
      "Epoch:  35 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [35/100]   Loss: 3.6739\n",
      "[VAL]  Epoch [35/100]   Loss: 4.8241\n",
      "Epoch:  36 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [36/100]   Loss: 3.6561\n",
      "[VAL]  Epoch [36/100]   Loss: 4.7863\n",
      "Epoch:  37 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [37/100]   Loss: 3.6354\n",
      "[VAL]  Epoch [37/100]   Loss: 4.8172\n",
      "Epoch:  38 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [38/100]   Loss: 3.6127\n",
      "[VAL]  Epoch [38/100]   Loss: 4.8042\n",
      "Epoch:  39 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [39/100]   Loss: 3.5956\n",
      "[VAL]  Epoch [39/100]   Loss: 4.7753\n",
      "Epoch:  40 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [40/100]   Loss: 3.5770\n",
      "[VAL]  Epoch [40/100]   Loss: 4.8421\n",
      "Epoch:  41 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [41/100]   Loss: 3.5629\n",
      "[VAL]  Epoch [41/100]   Loss: 4.8355\n",
      "Epoch:  42 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [42/100]   Loss: 3.5437\n",
      "[VAL]  Epoch [42/100]   Loss: 4.7410\n",
      "Epoch:  43 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [43/100]   Loss: 3.5313\n",
      "[VAL]  Epoch [43/100]   Loss: 4.8146\n",
      "Epoch:  44 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [44/100]   Loss: 3.5130\n",
      "[VAL]  Epoch [44/100]   Loss: 4.8825\n",
      "Epoch:  45 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [45/100]   Loss: 3.4956\n",
      "[VAL]  Epoch [45/100]   Loss: 4.8490\n",
      "Epoch:  46 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [46/100]   Loss: 3.4817\n",
      "[VAL]  Epoch [46/100]   Loss: 4.8802\n",
      "Epoch:  47 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [47/100]   Loss: 3.4667\n",
      "[VAL]  Epoch [47/100]   Loss: 4.8610\n",
      "Epoch:  48 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [48/100]   Loss: 3.4483\n",
      "[VAL]  Epoch [48/100]   Loss: 4.9207\n",
      "Epoch:  49 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [49/100]   Loss: 3.4360\n",
      "[VAL]  Epoch [49/100]   Loss: 4.8911\n",
      "Epoch:  50 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [50/100]   Loss: 3.4223\n",
      "[VAL]  Epoch [50/100]   Loss: 4.9158\n",
      "Epoch:  51 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [51/100]   Loss: 3.4077\n",
      "[VAL]  Epoch [51/100]   Loss: 4.9233\n",
      "Epoch:  52 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [52/100]   Loss: 3.3968\n",
      "[VAL]  Epoch [52/100]   Loss: 4.9485\n",
      "Epoch:  53 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [53/100]   Loss: 3.3787\n",
      "[VAL]  Epoch [53/100]   Loss: 5.0109\n",
      "Epoch:  54 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [54/100]   Loss: 3.3672\n",
      "[VAL]  Epoch [54/100]   Loss: 4.9321\n",
      "Epoch:  55 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [55/100]   Loss: 3.3592\n",
      "[VAL]  Epoch [55/100]   Loss: 4.8482\n",
      "Epoch:  56 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [56/100]   Loss: 3.3434\n",
      "[VAL]  Epoch [56/100]   Loss: 4.9889\n",
      "Epoch:  57 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [57/100]   Loss: 3.3351\n",
      "[VAL]  Epoch [57/100]   Loss: 5.0060\n",
      "Epoch:  58 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [58/100]   Loss: 3.3187\n",
      "[VAL]  Epoch [58/100]   Loss: 4.9630\n",
      "Epoch:  59 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [59/100]   Loss: 3.3102\n",
      "[VAL]  Epoch [59/100]   Loss: 5.0375\n",
      "Epoch:  60 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [60/100]   Loss: 3.2986\n",
      "[VAL]  Epoch [60/100]   Loss: 4.9619\n",
      "Epoch:  61 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [61/100]   Loss: 3.2905\n",
      "[VAL]  Epoch [61/100]   Loss: 4.9891\n",
      "Epoch:  62 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [62/100]   Loss: 3.2754\n",
      "[VAL]  Epoch [62/100]   Loss: 5.0192\n",
      "Epoch:  63 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [63/100]   Loss: 3.2621\n",
      "[VAL]  Epoch [63/100]   Loss: 4.9754\n",
      "Epoch:  64 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [64/100]   Loss: 3.2537\n",
      "[VAL]  Epoch [64/100]   Loss: 4.9835\n",
      "Epoch:  65 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [65/100]   Loss: 3.2404\n",
      "[VAL]  Epoch [65/100]   Loss: 5.1331\n",
      "Epoch:  66 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [66/100]   Loss: 3.2334\n",
      "[VAL]  Epoch [66/100]   Loss: 5.0445\n",
      "Epoch:  67 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [67/100]   Loss: 3.2219\n",
      "[VAL]  Epoch [67/100]   Loss: 5.0058\n",
      "Epoch:  68 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [68/100]   Loss: 3.2186\n",
      "[VAL]  Epoch [68/100]   Loss: 5.0326\n",
      "Epoch:  69 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [69/100]   Loss: 3.2035\n",
      "[VAL]  Epoch [69/100]   Loss: 4.9400\n",
      "Epoch:  70 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [70/100]   Loss: 3.1948\n",
      "[VAL]  Epoch [70/100]   Loss: 5.0962\n",
      "Epoch:  71 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [71/100]   Loss: 3.1854\n",
      "[VAL]  Epoch [71/100]   Loss: 5.0296\n",
      "Epoch:  72 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [72/100]   Loss: 3.1785\n",
      "[VAL]  Epoch [72/100]   Loss: 4.9731\n",
      "Epoch:  73 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [73/100]   Loss: 3.1690\n",
      "[VAL]  Epoch [73/100]   Loss: 5.0374\n",
      "Epoch:  74 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [74/100]   Loss: 3.1603\n",
      "[VAL]  Epoch [74/100]   Loss: 5.0738\n",
      "Epoch:  75 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [75/100]   Loss: 3.1527\n",
      "[VAL]  Epoch [75/100]   Loss: 5.0719\n",
      "Epoch:  76 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [76/100]   Loss: 3.1408\n",
      "[VAL]  Epoch [76/100]   Loss: 5.1459\n",
      "Epoch:  77 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [77/100]   Loss: 3.1335\n",
      "[VAL]  Epoch [77/100]   Loss: 4.9898\n",
      "Epoch:  78 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [78/100]   Loss: 3.1260\n",
      "[VAL]  Epoch [78/100]   Loss: 5.0524\n",
      "Epoch:  79 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [79/100]   Loss: 3.1198\n",
      "[VAL]  Epoch [79/100]   Loss: 4.9784\n",
      "Epoch:  80 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [80/100]   Loss: 3.1068\n",
      "[VAL]  Epoch [80/100]   Loss: 5.0554\n",
      "Epoch:  81 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [81/100]   Loss: 3.1008\n",
      "[VAL]  Epoch [81/100]   Loss: 5.0683\n",
      "Epoch:  82 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [82/100]   Loss: 3.0952\n",
      "[VAL]  Epoch [82/100]   Loss: 5.1030\n",
      "Epoch:  83 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [83/100]   Loss: 3.0859\n",
      "[VAL]  Epoch [83/100]   Loss: 5.0606\n",
      "Epoch:  84 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [84/100]   Loss: 3.0755\n",
      "[VAL]  Epoch [84/100]   Loss: 5.0748\n",
      "Epoch:  85 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [85/100]   Loss: 3.0642\n",
      "[VAL]  Epoch [85/100]   Loss: 5.0690\n",
      "Epoch:  86 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [86/100]   Loss: 3.0604\n",
      "[VAL]  Epoch [86/100]   Loss: 5.0562\n",
      "Epoch:  87 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [87/100]   Loss: 3.0516\n",
      "[VAL]  Epoch [87/100]   Loss: 5.1928\n",
      "Epoch:  88 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [88/100]   Loss: 3.0445\n",
      "[VAL]  Epoch [88/100]   Loss: 5.0466\n",
      "Epoch:  89 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [89/100]   Loss: 3.0394\n",
      "[VAL]  Epoch [89/100]   Loss: 5.0837\n",
      "Epoch:  90 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [90/100]   Loss: 3.0332\n",
      "[VAL]  Epoch [90/100]   Loss: 5.1188\n",
      "Epoch:  91 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [91/100]   Loss: 3.0277\n",
      "[VAL]  Epoch [91/100]   Loss: 5.0954\n",
      "Epoch:  92 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [92/100]   Loss: 3.0178\n",
      "[VAL]  Epoch [92/100]   Loss: 5.2573\n",
      "Epoch:  93 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [93/100]   Loss: 3.0122\n",
      "[VAL]  Epoch [93/100]   Loss: 5.1831\n",
      "Epoch:  94 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [94/100]   Loss: 3.0061\n",
      "[VAL]  Epoch [94/100]   Loss: 5.1663\n",
      "Epoch:  95 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [95/100]   Loss: 2.9987\n",
      "[VAL]  Epoch [95/100]   Loss: 5.1860\n",
      "Epoch:  96 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [96/100]   Loss: 2.9956\n",
      "[VAL]  Epoch [96/100]   Loss: 5.1192\n",
      "Epoch:  97 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [97/100]   Loss: 2.9833\n",
      "[VAL]  Epoch [97/100]   Loss: 5.1521\n",
      "Epoch:  98 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [98/100]   Loss: 2.9786\n",
      "[VAL]  Epoch [98/100]   Loss: 5.1490\n",
      "Epoch:  99 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [99/100]   Loss: 2.9737\n",
      "[VAL]  Epoch [99/100]   Loss: 5.2295\n",
      "Epoch:  100 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN]  Epoch [100/100]   Loss: 2.9629\n",
      "[VAL]  Epoch [100/100]   Loss: 5.1313\n"
     ]
    }
   ],
   "source": [
    "# best_nll = 1e30 \n",
    "print('best_nll: ', best_nll)\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print('Epoch: ', epoch+1, '/', NUM_EPOCHS)\n",
    "    trainer.train()\n",
    "    nll = trainer.test()\n",
    "    if nll < best_nll:\n",
    "        best_nll = nll\n",
    "        print(\"Saving model, predictions and generated output for epoch \"+str(epoch)+\" with NLL: \"+ str(best_nll))\n",
    "        trainer.save()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "id": "z2FmDqBCSwRf"
   },
   "outputs": [],
   "source": [
    "# Don't change these\n",
    "# plot training curves\n",
    "# plt.figure()\n",
    "# plt.plot(range(1, trainer.epochs + 1), trainer.train_losses, label='Training losses')\n",
    "# plt.plot(range(1, trainer.epochs + 1), trainer.val_losses, label='Validation losses')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('NLL')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "id": "ipdbmqaGSwRh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input | Output #0: while the group was en route , but only three were ultimately able to attack . None of them were | not considered to be a great deal of <unk> and\n",
      "Input | Output #1: <unk> , where he remained on loan until 30 June 2010 . <eol> = = = Return to Manchester United | World Cup = = = <eol> In the summer of\n",
      "Input | Output #2: 25 April 2013 , denoting shipments of 500 @,@ 000 copies . <eol> The song became One Direction 's fourth | single , and the first track from the album ,\n",
      "Input | Output #3: , and Bruce R. ) one daughter ( Wendy J. <unk> ) and two grandchildren , died in <unk> , | symbolising <unk> 515 to <unk> <unk> <unk> . <eol> =\n",
      "Input | Output #4: Warrior were examples of this type . Because their armor was so heavy , they could only carry a single | @-@ up for the first time in which the Chinese\n",
      "Input | Output #5: the embassy at 1 : 49 and landed on Guam at 2 : 23 ; twenty minutes later , Ambassador | the <unk> 's <unk> . <eol> = = = <unk>\n",
      "Input | Output #6: <unk> , $ 96 million USD ) . Damage was heaviest in South Korea , notably where it moved ashore | and was named Tropical Storm Jose . <eol> = =\n",
      "Input | Output #7: The <unk> were condemned as <unk> by <unk> , who saw the riots as hampering attempts to resolve the situation | . <eol> = = = = <unk> = = =\n",
      "Input | Output #8: by a decision made by the War Office in mid @-@ 1941 , as it was considering the equipment to | the parish . <eol> = = = Assassination of Eduardo\n",
      "Input | Output #9: Division crossed the <unk> at a number of places and climbed the hills quietly toward the 9th Infantry river line | . <eol> = = = <unk> = = = <eol>\n",
      "Input | Output #10: = <eol> = = = French VIII . Corps ( Corps <unk> ) = = = <eol> On 6 November | 1943 , the RAAF was reorganised by the RAAF to\n",
      "Input | Output #11: of the World from 9th Avenue \" . This is regarded as his most famous work . It is considered | a Schedule 1 @.@ 5 million toll @-@ hung sash\n",
      "Input | Output #12:  <unk> @-@ 10 , <unk> @-@ 12 , <unk> @-@ 16 , <unk> @-@ 17  were all converted | into a code system of track and field . The\n",
      "Input | Output #13: And now he has . \" <eol> = = Family = = <eol> <unk> lived 37 of his years in | the capital of <unk> . Busch was also a great\n",
      "Input | Output #14: Hell to which he has been condemned for <unk> . Eliot , in a letter to John <unk> dated 27 | June , he wrote a letter to the <unk> <unk>\n",
      "Input | Output #15: Luoyang area , fulfilling his duties in domestic affairs . <eol> In the autumn of <unk> , he met Li | <unk> , a member of the Order of the Brilliant\n",
      "Input | Output #16: Power said they enjoyed Block Ball and its number of stages , but wondered how its eight <unk> of memory | is not really . <eol> = = = = <unk>\n",
      "Input | Output #17: by Lloyd F. Lonergan . The cameraman was Jacques <unk> . <eol> = = Release and reception = = <eol> | Pokiri was released on September 1 , 2005 , and\n",
      "Input | Output #18: alone , the Austrians lost more than half their reserve artillery park , 6 @,@ 000 ( out of 8 | @,@ 000 ) and Canadians ( 1 @,@ 000 @-@\n",
      "Input | Output #19: while attacking a ship at <unk> in the Dutch East Indies ; the loss was compounded by the fact that | the Cambodian government had been forced into a defensive position\n",
      "Input | Output #20: first raised in 2007 by the member of parliament ( MP ) for <unk> . The gangsters may have run | out of privilege and was illiterate , the military ,\n",
      "Input | Output #21: Species are also non @-@ spiny <unk> and includes both large trees with stout stems up to 30 metres ( | 66 ft ) in diameter . The presence of a\n",
      "Input | Output #22: \" : specific design issues with the building 's energy efficiency included the fact that the largest room in the | city was the most important of the artistic functions .\n",
      "Input | Output #23: were reported to support over 300 @,@ 000 households in the Brazilian state of <unk> in 2005 , and in | the United States , the condom has been used in\n",
      "Input | Output #24: port . <unk> in Vietnam also warned for the potential of heavy rainfall due to the dissipating Tropical Depression <unk> | of the Lesser Antilles . <eol> = = = Hurricane\n",
      "Input | Output #25: T @-@ numbers in their tropical cyclone products . The following example is from discussion number 3 of Tropical Depression | Twenty One of the first season of the season in\n",
      "Input | Output #26: South Australia hosted the three @-@ game semi @-@ final series against the New South Wales <unk> . Both teams | were also selected as a tier for the sport of\n",
      "Input | Output #27: Perth from contention and secured the last finals spot for the <unk> . <eol> = = = Statistical leaders = | = = <eol> The game 's first game , which\n",
      "Input | Output #28: deemed it an \" amazing pop song \" , lauding the group 's falsetto and its \" head @-@ <unk> | [ and ] a falsetto guitar . \" <eol> =\n",
      "Input | Output #29: , but began patrolling the English Channel after <unk> @-@ 6 pioneered a route past British <unk> nets and mines | in the United States . <eol> = = = <unk>\n",
      "Input | Output #30: production executives to let him direct . He had already discussed the film with <unk> and Cohen , and felt | that the film was \" a great film \" .\n",
      "Input | Output #31: and Nick <unk> at Studio <unk> in Los Angeles , California , and was released on August 1 , 2006 | . <eol> = = = Ziltoid the Omniscient and hiatus\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# see generated output\n",
    "print (trainer.generated[-1]) # get last generated output"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "49babd242887c40fb16c5691cced875369a9ddf7aecdf16cfe0450dd8e53e3e4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
